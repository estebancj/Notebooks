{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"logos.jpg\" width=\"700\" />\n",
    "\n",
    "# Tensorflow example using Sina Weibo dataset\n",
    "\n",
    "The purpose of this notebook is to ilustrate the use of __Tensorflow__ package in an example that includes the construction of a neural network and the use of a supervised learning approach based in the back-propagation theory. The proposed example is based on dataset obtained from different social media interactions through the Sina Weibo platform in 2014 and 2015.\n",
    "\n",
    "Example main features:\n",
    "\n",
    "1. All the code was implemented in Python 3.5 for Windows and Python 2.7 for Linux/Mac https://www.python.org/ \n",
    "2. The  Python packages required to run the programs are the following:\n",
    "    * Jupyter notebook (Python interactive prompt) http://jupyter.org/index.html\n",
    "    * Tensorflow (Representation-classification) https://www.tensorflow.org/\n",
    "    * Numpy (classification) http://www.numpy.org/\n",
    "    * Matplotlib (visualization) https://matplotlib.org/\n",
    "    * Pandas (Data analysis) https://pandas.pydata.org/\n",
    "    * Xlrd (Data analysis) https://pypi.org/project/xlrd/\n",
    "3. The Tensorflow version used correspond to a standalone application which means that does not support the use of parallel \n",
    "   computations on GPUs.\n",
    "\n",
    "    \n",
    "## Step 1: Load the Sina Weibo dataset \n",
    "\n",
    "\n",
    "The dataset used in this notebook is an excerpt of the Sina Weibo platform (https://weibo.com/login.php) from September 2014 to May 2015 which contains 174,968 interactions associated to different users in the website each of them with distinct features related like year, city, gender, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>`year`</th>\n",
       "      <th>`month`</th>\n",
       "      <th>`day`</th>\n",
       "      <th>`hour`</th>\n",
       "      <th>`minute`</th>\n",
       "      <th>`lon`</th>\n",
       "      <th>`lat`</th>\n",
       "      <th>`user_id`</th>\n",
       "      <th>`gender`</th>\n",
       "      <th>`province`</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 21</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "      <th>Unnamed: 23</th>\n",
       "      <th>Unnamed: 24</th>\n",
       "      <th>Unnamed: 25</th>\n",
       "      <th>Unnamed: 26</th>\n",
       "      <th>Unnamed: 27</th>\n",
       "      <th>Unnamed: 28</th>\n",
       "      <th>Unnamed: 29</th>\n",
       "      <th>Unnamed: 30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>52</td>\n",
       "      <td>121.57677</td>\n",
       "      <td>31.335880</td>\n",
       "      <td>2203784962</td>\n",
       "      <td>'f'</td>\n",
       "      <td>'31'</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>47</td>\n",
       "      <td>121.54950</td>\n",
       "      <td>31.366600</td>\n",
       "      <td>1006306595</td>\n",
       "      <td>'m'</td>\n",
       "      <td>'100'</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>121.56900</td>\n",
       "      <td>31.349600</td>\n",
       "      <td>2027776417</td>\n",
       "      <td>'m'</td>\n",
       "      <td>'31'</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>52</td>\n",
       "      <td>121.56594</td>\n",
       "      <td>31.346882</td>\n",
       "      <td>3948063033</td>\n",
       "      <td>'m'</td>\n",
       "      <td>'100'</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>44</td>\n",
       "      <td>121.57879</td>\n",
       "      <td>31.341780</td>\n",
       "      <td>2275605075</td>\n",
       "      <td>'f'</td>\n",
       "      <td>'31'</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    `year`   `month`   `day`   `hour`   `minute`      `lon`      `lat`  \\\n",
       "0     2014         9       1       15         52  121.57677  31.335880   \n",
       "1     2014         9       1       16         47  121.54950  31.366600   \n",
       "2     2014         9       1       17          7  121.56900  31.349600   \n",
       "3     2014         9       1       19         52  121.56594  31.346882   \n",
       "4     2014         9       1       21         44  121.57879  31.341780   \n",
       "\n",
       "    `user_id`  `gender`  `province`     ...     Unnamed: 21  Unnamed: 22  \\\n",
       "0  2203784962       'f'        '31'     ...             NaN          NaN   \n",
       "1  1006306595       'm'       '100'     ...             NaN          NaN   \n",
       "2  2027776417       'm'        '31'     ...             NaN          NaN   \n",
       "3  3948063033       'm'       '100'     ...             NaN          NaN   \n",
       "4  2275605075       'f'        '31'     ...             NaN          NaN   \n",
       "\n",
       "   Unnamed: 23  Unnamed: 24  Unnamed: 25  Unnamed: 26 Unnamed: 27 Unnamed: 28  \\\n",
       "0          NaN          NaN          NaN          NaN         NaN         NaN   \n",
       "1          NaN          NaN          NaN          NaN         NaN         NaN   \n",
       "2          NaN          NaN          NaN          NaN         NaN         NaN   \n",
       "3          NaN          NaN          NaN          NaN         NaN         NaN   \n",
       "4          NaN          NaN          NaN          NaN         NaN         NaN   \n",
       "\n",
       "  Unnamed: 29 Unnamed: 30  \n",
       "0         NaN         NaN  \n",
       "1         NaN         NaN  \n",
       "2         NaN         NaN  \n",
       "3         NaN         NaN  \n",
       "4         NaN         NaN  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import Pandas package which help us to work with a structured dataset easily\n",
    "import pandas as pd\n",
    "#For displaying a Pandas table in the jupyter notebook\n",
    "from IPython.display import display, Markdown\n",
    "#Read Microsoft Excel file\n",
    "excel = pd.ExcelFile(\"2015_weibodata.xlsx\")\n",
    "#Load the dataset from the file as a Pandas table (called also dataframe)\n",
    "data= excel.parse(0) #Obtain first sheet from the Excel file\n",
    "#Show the first five rows of the table\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Preprocess the Sina Weibo dataset\n",
    "\n",
    "In this step, the unnecessary columns are discarded. Additionally the columns that have a string data type but have an integer nature are cast to the appropriate type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#Jupyter notebook command that disables the Python output for this code box.\n",
    "#Eliminate columns that don't have any meaningful information.\n",
    "cleanData = data[data.columns[:-14]]\n",
    "#Change the name of the columns\n",
    "cleanData.columns = [\"year\",\"month\",\"day\",\"hour\",\"minute\",\"lon\",\"lat\",\"user_id\",\"gender\",\n",
    "                     \"province\",\"city\",\"statusesCount\",\"followersCount\",\"friendsCount\", \n",
    "                     \"repostsCount\",\"commentsCount\",\"text\"]\n",
    "#Transform province and city columns from string to integer.\n",
    "cleanData[\"province\"]=cleanData[\"province\"].str[2:-1].apply(int)\n",
    "cleanData[\"city\"]=cleanData[\"city\"].str[2:-1].apply(int)\n",
    "#Transform lat and lon columns from string to float.\n",
    "cleanData[\"lat\"]=cleanData[\"lat\"].apply(float)\n",
    "cleanData[\"lon\"]=cleanData[\"lat\"].apply(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>user_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>province</th>\n",
       "      <th>city</th>\n",
       "      <th>statusesCount</th>\n",
       "      <th>followersCount</th>\n",
       "      <th>friendsCount</th>\n",
       "      <th>repostsCount</th>\n",
       "      <th>commentsCount</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>52</td>\n",
       "      <td>31.335880</td>\n",
       "      <td>31.335880</td>\n",
       "      <td>2203784962</td>\n",
       "      <td>'f'</td>\n",
       "      <td>31</td>\n",
       "      <td>15</td>\n",
       "      <td>750</td>\n",
       "      <td>128</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>'#一周综艺看点#我分享了专题《一周综艺看点》，刘烨哭断片，谢霆锋容祖儿坎坷出道经历，快来...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>47</td>\n",
       "      <td>31.366600</td>\n",
       "      <td>31.366600</td>\n",
       "      <td>1006306595</td>\n",
       "      <td>'m'</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>'最近心情很糟糕、也不知道怎么了 http://t.cn/Rh2hXjy');</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>31.349600</td>\n",
       "      <td>31.349600</td>\n",
       "      <td>2027776417</td>\n",
       "      <td>'m'</td>\n",
       "      <td>31</td>\n",
       "      <td>15</td>\n",
       "      <td>69</td>\n",
       "      <td>128</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>'#iphone6抢先送#看看你们这些爱慕虚荣的人，不就iphone6嘛，至于嘛？对于你们...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>52</td>\n",
       "      <td>31.346882</td>\n",
       "      <td>31.346882</td>\n",
       "      <td>3948063033</td>\n",
       "      <td>'m'</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>433</td>\n",
       "      <td>66</td>\n",
       "      <td>207</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>'人生几何总有些坎坷需要跨越，总有些责任需要担当，不断的跌倒，才有不变的顽强与收获:不变的...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>44</td>\n",
       "      <td>31.341780</td>\n",
       "      <td>31.341780</td>\n",
       "      <td>2275605075</td>\n",
       "      <td>'f'</td>\n",
       "      <td>31</td>\n",
       "      <td>1000</td>\n",
       "      <td>155</td>\n",
       "      <td>87</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>'心碎 ?? ??只是一瞬间 http://t.cn/Rh2fXOB');</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  day  hour  minute        lon        lat     user_id gender  \\\n",
       "0  2014      9    1    15      52  31.335880  31.335880  2203784962    'f'   \n",
       "1  2014      9    1    16      47  31.366600  31.366600  1006306595    'm'   \n",
       "2  2014      9    1    17       7  31.349600  31.349600  2027776417    'm'   \n",
       "3  2014      9    1    19      52  31.346882  31.346882  3948063033    'm'   \n",
       "4  2014      9    1    21      44  31.341780  31.341780  2275605075    'f'   \n",
       "\n",
       "   province  city  statusesCount  followersCount  friendsCount  repostsCount  \\\n",
       "0        31    15            750             128            84             0   \n",
       "1       100  1000              1               0             0             0   \n",
       "2        31    15             69             128           107             0   \n",
       "3       100  1000            433              66           207             0   \n",
       "4        31  1000            155              87           119             0   \n",
       "\n",
       "   commentsCount                                               text  \n",
       "0              0   '#一周综艺看点#我分享了专题《一周综艺看点》，刘烨哭断片，谢霆锋容祖儿坎坷出道经历，快来...  \n",
       "1              0            '最近心情很糟糕、也不知道怎么了 http://t.cn/Rh2hXjy');  \n",
       "2              0   '#iphone6抢先送#看看你们这些爱慕虚荣的人，不就iphone6嘛，至于嘛？对于你们...  \n",
       "3              0   '人生几何总有些坎坷需要跨越，总有些责任需要担当，不断的跌倒，才有不变的顽强与收获:不变的...  \n",
       "4              3              '心碎 ?? ??只是一瞬间 http://t.cn/Rh2fXOB');  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Obtain the first five rows of the table\n",
    "cleanData.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Select features from the Sina Weibo dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Select the __gender__ column as target label to be used in a classification process using a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 'f'    109416\n",
       " 'm'     65551\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np            \n",
    "labelCol='gender'\n",
    "#Eliminate unnecessary characters from the gender column and transform it to string.\n",
    "labels= np.array(cleanData.loc[:,labelCol].str[2:-1].apply(str), np.str) \n",
    "#Transform the string column to integer values which are mandatory for the neural network function.\n",
    "labels[labels=='m'] = 0\n",
    "labels[labels=='f'] = 1\n",
    "labelsDatasetGender= np.array(labels, np.int32) \n",
    "#Show the number of rows associated to each gender.\n",
    "cleanData['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Considering the different columns available in the dataset, obtain a subset of numeric values as features to construct a neural network based on the back propagation theory. It is important to highlight that the non-numeric features are discarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#According to the attributes nature and type, select the most representative ones as features for a classification process\n",
    "FeatureCols = [\"year\",\"day\",\"hour\",\"minute\",\"lon\",\"lat\",\"province\",\"city\",\"statusesCount\",\n",
    "               \"followersCount\",\"friendsCount\", \"repostsCount\",\"commentsCount\"]\n",
    "cleanData=cleanData.loc[:, FeatureCols]\n",
    "#Subset the features into a new variable.\n",
    "featuresDataset = np.array(cleanData, np.int32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Split training and test rows for the classification process. Use the first one hundred and fifty thousand\n",
    " rows for training and the remaining for test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the dataset following an approach of 80% for training and 20% for test.\n",
    "training = featuresDataset[:150000]\n",
    "test = featuresDataset[150000:]\n",
    "trainingLabels=labelsDatasetGender[:150000]\n",
    "testLabels=labelsDatasetGender[150000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create a neural network to predict Sina Weibo users __gender__ \n",
    "\n",
    "Create a neural network with an input layer of thirteen neurons (number of columns selected), three hidden layers of three hundred neurons each of them and a final output of two neurons taking in mind the __gender__ classification process. It is important to highlight that for the creation of the neural network a predefined function called DNNClassifier is used, considering a gradient descent optimizer and softmax cross entropy for the error rate.\n",
    "\n",
    "<img src=\"backPropagation3.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\ESTEBA~1\\AppData\\Local\\Temp\\tmpvxgkp6l_\n",
      "INFO:tensorflow:Using config: {'_keep_checkpoint_every_n_hours': 10000, '_task_type': 'worker', '_is_chief': True, '_keep_checkpoint_max': 5, '_task_id': 0, '_tf_random_seed': None, '_model_dir': 'C:\\\\Users\\\\ESTEBA~1\\\\AppData\\\\Local\\\\Temp\\\\tmpvxgkp6l_', '_save_checkpoints_secs': 600, '_session_config': None, '_master': '', '_save_summary_steps': 100, '_service': None, '_save_checkpoints_steps': None, '_train_distribute': None, '_log_step_count_steps': 100, '_num_ps_replicas': 0, '_evaluation_master': '', '_global_id_in_cluster': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000002A53F164F60>, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\ESTEBA~1\\AppData\\Local\\Temp\\tmpvxgkp6l_\\model.ckpt.\n",
      "INFO:tensorflow:loss = 78758.93, step = 1\n",
      "INFO:tensorflow:global_step/sec: 63.202\n",
      "INFO:tensorflow:loss = 3516.6187, step = 101 (1.583 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.8573\n",
      "INFO:tensorflow:loss = 4375.864, step = 201 (1.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.7231\n",
      "INFO:tensorflow:loss = 2311.0444, step = 301 (1.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.9582\n",
      "INFO:tensorflow:loss = 331.34555, step = 401 (1.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.213\n",
      "INFO:tensorflow:loss = 313.88174, step = 501 (1.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.6087\n",
      "INFO:tensorflow:loss = 1226.4994, step = 601 (1.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.9961\n",
      "INFO:tensorflow:loss = 325.8789, step = 701 (1.351 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.666\n",
      "INFO:tensorflow:loss = 298.03067, step = 801 (1.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.5089\n",
      "INFO:tensorflow:loss = 492.19055, step = 901 (1.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.6214\n",
      "INFO:tensorflow:loss = 329.74258, step = 1001 (1.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.4795\n",
      "INFO:tensorflow:loss = 287.87708, step = 1101 (1.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.5451\n",
      "INFO:tensorflow:loss = 339.47644, step = 1201 (1.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.2297\n",
      "INFO:tensorflow:loss = 322.94962, step = 1301 (1.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.8473\n",
      "INFO:tensorflow:loss = 305.53436, step = 1401 (1.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.5766\n",
      "INFO:tensorflow:loss = 315.7874, step = 1501 (1.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.3699\n",
      "INFO:tensorflow:loss = 326.79388, step = 1601 (1.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.7934\n",
      "INFO:tensorflow:loss = 281.88434, step = 1701 (1.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.3853\n",
      "INFO:tensorflow:loss = 306.85263, step = 1801 (1.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.8761\n",
      "INFO:tensorflow:loss = 316.15198, step = 1901 (1.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.4839\n",
      "INFO:tensorflow:loss = 284.05023, step = 2001 (1.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.188\n",
      "INFO:tensorflow:loss = 311.25024, step = 2101 (1.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.7994\n",
      "INFO:tensorflow:loss = 317.82568, step = 2201 (1.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.6014\n",
      "INFO:tensorflow:loss = 288.96143, step = 2301 (1.596 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.6659\n",
      "INFO:tensorflow:loss = 306.9742, step = 2401 (1.478 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.3\n",
      "INFO:tensorflow:loss = 315.0352, step = 2501 (1.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.7467\n",
      "INFO:tensorflow:loss = 295.05502, step = 2601 (1.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.5181\n",
      "INFO:tensorflow:loss = 294.20654, step = 2701 (1.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.2703\n",
      "INFO:tensorflow:loss = 303.72836, step = 2801 (1.509 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.5212\n",
      "INFO:tensorflow:loss = 287.73352, step = 2901 (1.551 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.9943\n",
      "INFO:tensorflow:loss = 303.05283, step = 3001 (1.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.4647\n",
      "INFO:tensorflow:loss = 309.38034, step = 3101 (1.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.672\n",
      "INFO:tensorflow:loss = 290.56842, step = 3201 (1.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.4286\n",
      "INFO:tensorflow:loss = 304.06116, step = 3301 (1.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.4725\n",
      "INFO:tensorflow:loss = 305.90762, step = 3401 (1.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.6899\n",
      "INFO:tensorflow:loss = 301.1169, step = 3501 (1.570 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.7571\n",
      "INFO:tensorflow:loss = 297.68207, step = 3601 (1.522 sec)\n",
      "INFO:tensorflow:global_step/sec: 57.1147\n",
      "INFO:tensorflow:loss = 298.83566, step = 3701 (1.751 sec)\n",
      "INFO:tensorflow:global_step/sec: 59.965\n",
      "INFO:tensorflow:loss = 290.8143, step = 3801 (1.666 sec)\n",
      "INFO:tensorflow:global_step/sec: 58.5869\n",
      "INFO:tensorflow:loss = 301.41406, step = 3901 (1.706 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.9161\n",
      "INFO:tensorflow:loss = 297.87976, step = 4001 (1.565 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.5794\n",
      "INFO:tensorflow:loss = 288.48615, step = 4101 (1.574 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.7115\n",
      "INFO:tensorflow:loss = 299.47244, step = 4201 (1.595 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.7219\n",
      "INFO:tensorflow:loss = 302.71045, step = 4301 (1.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.7993\n",
      "INFO:tensorflow:loss = 286.16525, step = 4401 (1.434 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.0242\n",
      "INFO:tensorflow:loss = 302.77524, step = 4501 (1.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.1973\n",
      "INFO:tensorflow:loss = 306.27515, step = 4601 (1.533 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.3927\n",
      "INFO:tensorflow:loss = 284.74323, step = 4701 (1.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.3975\n",
      "INFO:tensorflow:loss = 316.36063, step = 4801 (1.422 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.1321\n",
      "INFO:tensorflow:loss = 303.08984, step = 4901 (1.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.4562\n",
      "INFO:tensorflow:loss = 270.4009, step = 5001 (1.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.672\n",
      "INFO:tensorflow:loss = 301.09393, step = 5101 (1.543 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.41\n",
      "INFO:tensorflow:loss = 302.91745, step = 5201 (1.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.609\n",
      "INFO:tensorflow:loss = 285.43167, step = 5301 (1.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.9592\n",
      "INFO:tensorflow:loss = 292.45233, step = 5401 (1.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.2598\n",
      "INFO:tensorflow:loss = 308.8532, step = 5501 (1.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.667\n",
      "INFO:tensorflow:loss = 277.89166, step = 5601 (1.522 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.3875\n",
      "INFO:tensorflow:loss = 296.45828, step = 5701 (1.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.846\n",
      "INFO:tensorflow:loss = 299.99432, step = 5801 (1.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 58.4785\n",
      "INFO:tensorflow:loss = 285.99002, step = 5901 (1.711 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.6693\n",
      "INFO:tensorflow:loss = 304.86398, step = 6001 (1.596 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.3211\n",
      "INFO:tensorflow:loss = 306.80307, step = 6101 (1.608 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.3968\n",
      "INFO:tensorflow:loss = 272.82443, step = 6201 (1.551 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.1517\n",
      "INFO:tensorflow:loss = 313.27167, step = 6301 (1.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.5065\n",
      "INFO:tensorflow:loss = 287.44467, step = 6401 (1.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.6525\n",
      "INFO:tensorflow:loss = 267.7783, step = 6501 (1.437 sec)\n",
      "INFO:tensorflow:global_step/sec: 61.3625\n",
      "INFO:tensorflow:loss = 309.03006, step = 6601 (1.628 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.821\n",
      "INFO:tensorflow:loss = 296.972, step = 6701 (1.568 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.3887\n",
      "INFO:tensorflow:loss = 293.2727, step = 6801 (1.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.2484\n",
      "INFO:tensorflow:loss = 313.40915, step = 6901 (1.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 59.8255\n",
      "INFO:tensorflow:loss = 304.6567, step = 7001 (1.672 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.2337\n",
      "INFO:tensorflow:loss = 280.32773, step = 7101 (1.993 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.4717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 295.93842, step = 7201 (2.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 52.3908\n",
      "INFO:tensorflow:loss = 304.83582, step = 7301 (1.907 sec)\n",
      "INFO:tensorflow:global_step/sec: 58.4643\n",
      "INFO:tensorflow:loss = 278.3709, step = 7401 (1.708 sec)\n",
      "INFO:tensorflow:global_step/sec: 59.0404\n",
      "INFO:tensorflow:loss = 315.68298, step = 7501 (1.696 sec)\n",
      "INFO:tensorflow:global_step/sec: 56.8494\n",
      "INFO:tensorflow:loss = 303.99515, step = 7601 (1.757 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.6962\n",
      "INFO:tensorflow:loss = 280.74194, step = 7701 (1.829 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.5464\n",
      "INFO:tensorflow:loss = 303.0869, step = 7801 (2.017 sec)\n",
      "INFO:tensorflow:global_step/sec: 56.5193\n",
      "INFO:tensorflow:loss = 294.41406, step = 7901 (1.770 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.2193\n",
      "INFO:tensorflow:loss = 287.41727, step = 8001 (1.928 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.6074\n",
      "INFO:tensorflow:loss = 293.353, step = 8101 (1.816 sec)\n",
      "INFO:tensorflow:global_step/sec: 58.5151\n",
      "INFO:tensorflow:loss = 295.64035, step = 8201 (1.709 sec)\n",
      "INFO:tensorflow:global_step/sec: 59.4211\n",
      "INFO:tensorflow:loss = 284.97897, step = 8301 (1.683 sec)\n",
      "INFO:tensorflow:global_step/sec: 58.4437\n",
      "INFO:tensorflow:loss = 302.16693, step = 8401 (1.711 sec)\n",
      "INFO:tensorflow:global_step/sec: 56.0212\n",
      "INFO:tensorflow:loss = 302.29178, step = 8501 (1.786 sec)\n",
      "INFO:tensorflow:global_step/sec: 58.0747\n",
      "INFO:tensorflow:loss = 283.41672, step = 8601 (1.726 sec)\n",
      "INFO:tensorflow:global_step/sec: 58.3607\n",
      "INFO:tensorflow:loss = 299.8918, step = 8701 (1.714 sec)\n",
      "INFO:tensorflow:global_step/sec: 52.619\n",
      "INFO:tensorflow:loss = 298.35788, step = 8801 (1.901 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.5791\n",
      "INFO:tensorflow:loss = 292.99377, step = 8901 (1.825 sec)\n",
      "INFO:tensorflow:global_step/sec: 57.8543\n",
      "INFO:tensorflow:loss = 291.41388, step = 9001 (1.728 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.5522\n",
      "INFO:tensorflow:loss = 299.4513, step = 9101 (1.574 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.0073\n",
      "INFO:tensorflow:loss = 283.33508, step = 9201 (1.613 sec)\n",
      "INFO:tensorflow:global_step/sec: 61.2492\n",
      "INFO:tensorflow:loss = 309.8947, step = 9301 (1.634 sec)\n",
      "INFO:tensorflow:global_step/sec: 56.1258\n",
      "INFO:tensorflow:loss = 307.2793, step = 9401 (1.782 sec)\n",
      "INFO:tensorflow:global_step/sec: 51.5762\n",
      "INFO:tensorflow:loss = 288.02896, step = 9501 (1.939 sec)\n",
      "INFO:tensorflow:global_step/sec: 58.5678\n",
      "INFO:tensorflow:loss = 293.11252, step = 9601 (1.707 sec)\n",
      "INFO:tensorflow:global_step/sec: 58.2013\n",
      "INFO:tensorflow:loss = 301.82364, step = 9701 (1.717 sec)\n",
      "INFO:tensorflow:global_step/sec: 56.7955\n",
      "INFO:tensorflow:loss = 284.2278, step = 9801 (1.766 sec)\n",
      "INFO:tensorflow:global_step/sec: 56.1622\n",
      "INFO:tensorflow:loss = 295.66162, step = 9901 (1.780 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.3498\n",
      "INFO:tensorflow:loss = 302.574, step = 10001 (2.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.2718\n",
      "INFO:tensorflow:loss = 278.98453, step = 10101 (1.877 sec)\n",
      "INFO:tensorflow:global_step/sec: 56.8234\n",
      "INFO:tensorflow:loss = 294.22263, step = 10201 (1.759 sec)\n",
      "INFO:tensorflow:global_step/sec: 58.8126\n",
      "INFO:tensorflow:loss = 295.85718, step = 10301 (1.700 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.1663\n",
      "INFO:tensorflow:loss = 278.12762, step = 10401 (1.815 sec)\n",
      "INFO:tensorflow:global_step/sec: 58.994\n",
      "INFO:tensorflow:loss = 296.01437, step = 10501 (1.694 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.785\n",
      "INFO:tensorflow:loss = 305.15256, step = 10601 (1.568 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.3353\n",
      "INFO:tensorflow:loss = 279.70502, step = 10701 (1.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.1509\n",
      "INFO:tensorflow:loss = 298.30106, step = 10801 (1.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.0223\n",
      "INFO:tensorflow:loss = 309.71585, step = 10901 (1.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.8836\n",
      "INFO:tensorflow:loss = 272.16095, step = 11001 (1.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.9534\n",
      "INFO:tensorflow:loss = 299.43964, step = 11101 (1.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.931\n",
      "INFO:tensorflow:loss = 299.00476, step = 11201 (1.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.0133\n",
      "INFO:tensorflow:loss = 283.04306, step = 11301 (1.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.207\n",
      "INFO:tensorflow:loss = 303.98712, step = 11401 (1.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.4807\n",
      "INFO:tensorflow:loss = 307.34995, step = 11501 (1.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.7688\n",
      "INFO:tensorflow:loss = 281.82346, step = 11601 (1.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.9491\n",
      "INFO:tensorflow:loss = 298.9407, step = 11701 (1.451 sec)\n",
      "INFO:tensorflow:global_step/sec: 61.0651\n",
      "INFO:tensorflow:loss = 291.7099, step = 11801 (1.640 sec)\n",
      "INFO:tensorflow:global_step/sec: 61.9238\n",
      "INFO:tensorflow:loss = 278.78586, step = 11901 (1.612 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 12000 into C:\\Users\\ESTEBA~1\\AppData\\Local\\Temp\\tmpvxgkp6l_\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 305.4312.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x2a53bf92dd8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#Store the number of features (thirteen) to be used in the neural network.\n",
    "#https://www.tensorflow.org/api_docs/python/tf/feature_column/numeric_column\n",
    "NNFeatureCols  = [tf.feature_column.numeric_column(\"X\", shape=[13])]\n",
    "\"\"\"\n",
    "Create a neural network specifying the the number of hidden layers, the number of target labels (f=1 or m=0) and \n",
    "the number of features per row in the table.\n",
    "\"\"\"\n",
    "#https://www.tensorflow.org/api_docs/python/tf/estimator/DNNClassifier\n",
    "dnnClf = tf.estimator.DNNClassifier(hidden_units=[300,300,300], n_classes=2,feature_columns=NNFeatureCols)\n",
    "#Feed the training data as well as the epoch number and batch size into the model.\n",
    "#https://www.tensorflow.org/api_docs/python/tf/estimator/inputs/numpy_input_fn\n",
    "#One Epoch is when an ENTIRE dataset is passed forward and backward through the neural network only ONCE\n",
    "#Since, one epoch is too big to feed to the computer at once we divide it in several smaller batches\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"X\": training}, y=trainingLabels, num_epochs=40, batch_size=500, shuffle=True)\n",
    "#Train the neural network\n",
    "dnnClf.train(input_fn=input_fn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Test the neural network\n",
    "\n",
    "1. Evaluate the proposed neural network model in the Complete Sina Weibo test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-07-09-01:10:13\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ESTEBA~1\\AppData\\Local\\Temp\\tmpvxgkp6l_\\model.ckpt-12000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-07-09-01:10:15\n",
      "INFO:tensorflow:Saving dict for global step 12000: accuracy = 0.6591901, accuracy_baseline = 0.66111267, auc = 0.61261624, auc_precision_recall = 0.73273844, average_loss = 0.6338437, global_step = 12000, label/mean = 0.66111267, loss = 80.7407, precision = 0.69651544, prediction/mean = 0.6208308, recall = 0.85859686\n",
      "{'average_loss': 0.6338437, 'label/mean': 0.66111267, 'auc': 0.61261624, 'accuracy': 0.6591901, 'prediction/mean': 0.6208308, 'accuracy_baseline': 0.66111267, 'global_step': 12000, 'auc_precision_recall': 0.73273844, 'loss': 80.7407, 'precision': 0.69651544, 'recall': 0.85859686}\n"
     ]
    }
   ],
   "source": [
    "#https://www.tensorflow.org/api_docs/python/tf/estimator/inputs/numpy_input_fn\n",
    "#Use the trained model to predict the gender of the social media interactions associated to the test dataset\n",
    "#Feed the test data into the model\n",
    "testFunction = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"X\": test}, y=testLabels, shuffle=False)\n",
    "#Evaluate the results according to accuracy, precision, recall among other metrics\n",
    "eval_results = dnnClf.evaluate(input_fn=testFunction)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Show the evaluation for a specific test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ESTEBA~1\\AppData\\Local\\Temp\\tmpvxgkp6l_\\model.ckpt-12000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "{'class_ids': array([1], dtype=int64), 'probabilities': array([0.2408241, 0.7591759], dtype=float32), 'logistic': array([0.7591759], dtype=float32), 'logits': array([1.1481667], dtype=float32), 'classes': array([b'1'], dtype=object)}\n"
     ]
    }
   ],
   "source": [
    "#Iterable object that helps us to see the results individually\n",
    "IterPred= dnnClf.predict(input_fn=testFunction)\n",
    "#Get first prediction\n",
    "y_pred = list(IterPred)\n",
    "print(y_pred[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conlusions\n",
    "\n",
    "- What we seen so far:\n",
    "    1. Load an specific dataset based on a Excel file format.\n",
    "    2. Preprocess the information associated to the dataset.\n",
    "    3. Creation of a Neural network using a __reduce version of the Tensorflow package__.\n",
    "        * Input layer with thirteen neurons.\n",
    "        * three hiden layers of three hundred neurons.\n",
    "        * One ouput layer of two neurons, one for each posible gender in the dataset (0=m and 1=f).\n",
    "    4. Use of the DNNClassifier function which encapsulates all the complexity associated to the creation of a neural network.\n",
    "    5. Creation of training and test subsets from the Sina Weibo data.\n",
    "    5. Creation of a model using the training subset provided.\n",
    "    6. Evaluation of the test subset using the model created.\n",
    "- Obtained results highlight the following findings:  \n",
    "    1. Tensorflow permits to create a graph where nodes are operations and edges are information that flows from one operation to others.\n",
    "    2. There are multiple predefined functions in Tensorflow that can help to create a neural network easily.\n",
    "    3. If the computations were dense, we can distribute the job processing among different computers or gpus using Tensorflow API."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
